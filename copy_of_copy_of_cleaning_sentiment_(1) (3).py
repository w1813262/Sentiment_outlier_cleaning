# -*- coding: utf-8 -*-
"""Copy_of_Copy_of_Cleaning_Sentiment (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VY53fb-IhdcU8B0TztiDVn4a99YA7qqY
"""

# Commented out IPython magic to ensure Python compatibility.
#  Import library
import pandas as pd
import numpy as np
from scipy.stats import zscore
from scipy import stats
from wordcloud import WordCloud
from textblob import TextBlob
from tqdm import tqdm 
import seaborn as sns
import matplotlib.pyplot as plt

# %matplotlib inline

from google.colab import files
uploaded= files.upload()

final_data = pd.read_csv('BBCbreaking_fulldata.csv')
final_data.head()

pd.set_option("display.max.columns", None)
pd.set_option("display.precision", 2)

final_data.tail()

# Information about the data
final_data.info()

"""<hr>

## **Cleaning the data**
"""

#@title
# Check the shape of final data
final_data.shape

# check the Screen Name of Twitter user
final_data['screenname'].unique()

# check the ID of Twitter user
final_data['ID'].unique()

#  Need only BCCBreaking Tweet
# Skip the BBCSport tweet
final_data = final_data[final_data['ID'] == '@BBCBreaking']
final_data = final_data[final_data['screenname'] == 'BBC Breaking News']

final_data["Video"].unique()

final_data["Video"].unique()

final_data["retweeted"].unique()

# Change the True / False to 1/0
final_data["Video"] = final_data["Video"].astype(int)

final_data["retweeted"] = final_data["retweeted"].astype(int)

final_data["pinned"] = final_data["pinned"].astype(int)

# Change the 1K to 1000 and 1m 
final_data.likes = (final_data.likes.replace(r'[KM]+$', '', regex=True).astype(float) * \
                    final_data.likes.str.extract(r'[\d\.]+([KM]+)', expand=False)
                    .fillna(1)
                    .replace(['K','M'], [10**3, 10**6]).astype(int))

final_data.retweets = (final_data.retweets.replace(r'[KM]+$', '', regex=True).astype(float) * \
                    final_data.retweets.str.extract(r'[\d\.]+([KM]+)', expand=False)
                    .fillna(1)
                    .replace(['K','M'], [10**3, 10**6]).astype(int))

final_data.replies = (final_data.replies.replace(r'[KM]+$', '', regex=True).astype(float) * \
                    final_data.replies.str.extract(r'[\d\.]+([KM]+)', expand=False)
                    .fillna(1)
                    .replace(['K','M'], [10**3, 10**6]).astype(int))

final_data.shape

final_data['time'] = pd.to_datetime(final_data.time, format='%Y-%m-%d')

final_data['time']

"""<hr>

 **Remove Outlier**
"""

new_data = pd.DataFrame(final_data)

sns.boxplot(x=new_data['replies'])

sns.boxplot(x=new_data['likes'])

sns.boxplot(x=new_data['retweets'])

data = pd.DataFrame()
data = new_data[['replies','retweets','likes']]
data.head()

data.shape

data.astype(int)

Q1 = np.percentile(data, 25,interpolation = 'midpoint')

Q3 = np.percentile(data, 75,interpolation = 'midpoint')
IQR = Q3 - Q1

print("Old Shape: ", new_data.shape)

# Upper bound

upper = Q3+1.5*IQR
# Lower bound
lower = Q1-1.5*IQR


data_no_outlier = new_data[(new_data.replies>lower)&(new_data.replies<upper)]
data_no_outlier = new_data[(new_data.retweets>lower)&(new_data.retweets<upper)]
data_no_outlier = new_data[(new_data.likes>lower)&(new_data.likes<upper)]
print("New Shape: ", data_no_outlier.shape)
data_no_outlier

sns.boxplot(x=data_no_outlier['likes'])

sns.boxplot(x=data_no_outlier['retweets'])

sns.boxplot(x=data_no_outlier['replies'])

"""<hr>

## **Sentiment Analysis**
"""

final_data = data_no_outlier

final_data.shape

final_data.to_csv("Cleans_data.csv")

final_data.rename(columns = {'content':'Tweets'}, inplace = True)
# 
final_data.head()

"""<hr>

 **Clean the text**
"""

#  import
import re
from textblob import TextBlob

# Create a function to clean the tweets
def cleanTxt(tweet):
  tweet = re.sub(r"@[\w]*", '', tweet)
  tweet = re.sub(r'#', '',tweet) # removing the symbol
  tweet = re.sub(r'RT[\s]+', '', tweet) # Removing RT
  tweet = re.sub(r'https?:\/\/\S+', '', tweet)# Remove the hyper link
  return tweet

final_data['Tweets']=final_data['Tweets'].apply(str)

final_data['Tweets'] = final_data['Tweets'].apply(cleanTxt)

# remove special characters, numbers, punctuations
final_data['Tweets'] = final_data['Tweets'].str.replace("[^a-zA-Z#]", " ")

# create a function to get the subjectivity
def getSubjectivity(tweet):
  return TextBlob(tweet).sentiment.subjectivity

# Create a funtion to get the polarity
def getPolarity(tweet):
  return TextBlob(tweet).sentiment.polarity

# Create two new columns
final_data['Subjectivity'] = final_data['Tweets'].apply(getSubjectivity)
final_data['Polarity'] = final_data['Tweets'].apply(getPolarity)

# Plot the word cloud 
all_words = ' '.join([text for text in final_data['Tweets']])

wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(all_words)

plt.figure(figsize=(10, 7))
plt.imshow(wordcloud, interpolation="bilinear")
plt.axis('off')
plt.show()

# Show the new dataframe with the new columns
final_data.head(10)

# Create a function to compute the negative, neutral and positive analysis
def getAnalysis(score):
  if score < 0:
    return 'Negative'
  elif score == 0:
    return 'Neutral'
  else:
    return 'Positive'

final_data['Analysis'] = final_data['Polarity'].apply(getAnalysis)
# show the dataFrame
final_data.head(10)

plt.figure(figsize=(8,6))

plt.scatter(final_data['Polarity'], final_data['Subjectivity'], color = 'Blue')

plt.title('Sentiment Analysis')
plt.xlabel('Polarity')
plt.ylabel('Subjectivity')
plt.show()

final_data.to_csv("final_data.csv")

# PLot the visualize the  Value Counts
plt.title('Sentiment Analysis')
plt.xlabel('Sentiment')
plt.ylabel('Counts')
final_data['Analysis'].value_counts().plot(kind= 'bar')
plt.show()

# show the value counts 

final_data['Analysis'].value_counts()

# Get the percentage of positive tweets
ptweets = final_data[final_data.Analysis == 'Positive']
ptweets = ptweets['Tweets']
round( (ptweets.shape[0]/ final_data.shape[0]) *100, 2)

# Get the percentage of Negative tweets
ptweets = final_data[final_data.Analysis == 'Negative']
ptweets = ptweets['Tweets']
round( (ptweets.shape[0]/ final_data.shape[0]) *100, 2)

# Get the percentage of Neutral tweets
ptweets = final_data[final_data.Analysis == 'Neutral']
ptweets = ptweets['Tweets']
round( (ptweets.shape[0]/ final_data.shape[0]) *100, 2)